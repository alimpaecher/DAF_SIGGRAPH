\section{Introduction}

% Animation algorithms generally fall into one of two categories. \emph{Model-based} methods use physical equations or procedural methods to generate successive frames of animation, while \emph{data-driven} methods rely on lengthy precomputation. 

\textbf{hey guys... don't hate here... this is a wild a woolly first draft of the intro, but I think that it has many of the ideas that it want in it}

Data-driven techniques have enabled the real-time animation of stunningly complex phenomena which are either too expensive to simulate in real-time (such as the folds and wrinkles in high-resolution cloth) or for which we have no good models (such as human motion). However, the central argument against such precomputation-based approaches rests on the curse of dimensionality: it impossible to capture ``everything'' because each additional simulation condition (e.g. wind direction) exponentially explodes the dynamical space. For this reason, virtually all previous work in data-driven animation has studied phenomena in a very controlled settings with few exciting modes, and under the strict assumption that the phenomenon will return to a single, rest configuration. \textbf{[Cite a few James papers and Treuille papers here.]}

In light of the recent massive growth in the availability of large amounts of computing capability we believe that it is time to revisit this argument: while it might not be tractable to capture \emph{everything} about a complex dynamical system, it may just be possible to capture \emph{almost everything important}. This mirrors a growing trend in computer science which have looked at theoretically infinite spaces -- like machine translation -- and have captured ``almost everything'' about translation simply by using a sufficiently large corpus of texts~\cite{Halevy:2009}.

In this paper, we focus the precomputation of secondary clothing effects on a character animated through a finite motion graph. We introduce the notion of a \emph{secondary motion graph}: for each state in the primary motion graph (in this case, the character position) there may be many corresponding states in the secondary motion graph (in this case, the position of clothes on the body). However, because cloth is a dynamical system -- the state of the cloth depends on previous cloth states -- thus the secondary motion graph can be vastly more complex than the primary motion graph. We even observe \emph{bifurcations} in the dynamics where the cloth can never return to certain previous states.

We report our findings performing massive exploration of the secondary motion graph space. In contrast to previous work on precomputation, we simulate significantly more data to build a large scale portrait of the phase space of the dynamics. For example, some of our examples represent over one month \textbf{[what's the right answer here?]} of continuous wall clock precomputation time. In contrast to many data-driven techniques, our model provides guaranteed bounds on the error of the approximation for the precomputed model. We show that by tracking this error as the model is computed, it is possible to detect bifurcations and estimate the convergence of the precomputed model. Finally, we show that even for certain large motion graphs, it is possible to explore the entire secondary dynamical space to within a low error tolerance -- essentially, to precompute almost everything important -- and that the resulting model can be compressed to a reasonably small memory footprint. On a practical level, these results allow us to capture the effect of high-resolution off-line cloth simulation in real-time while supporting a very large state space, including bifurcations. Alternatively, our model is designed to support ``endless exploration'' of the dynamical space wherein an ever enlargening portrait of the phase space is constructed, to build a database which could in principle be streamed to clients in mealtime in a cloud-based application. Thus, in contrast to previous precomputation approaches which typically require carefully setting up the exact scenarios to be precomputed.

In this sense, the underlying set of motions generated by the character is finite, but there remains a potentially infinite set of cloth motion given this motion graph. Indeed, the 

\textbf{another important point to make here -- related to the absolute error bounds -- is that we can tell the error only manifests at a sparse set of frames making it possible to verify all the error entirely}

% \section{Outline}
% 
% - related work

%   
% 
% 

%     

%   - 
% 
% == other possible results ==
% 
