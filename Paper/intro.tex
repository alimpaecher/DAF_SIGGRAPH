\section{Introduction}

The big data revolution is profoundly transforming computer science
and society. Problems which frustrated generations of researchers,
such as machine translation and object recognition, suddenly became
``solved'' when run on large datasets. However, the scarcity of data
in many domains threatens the continued success of the big data
approach. We now see a schism between domains for which large
datasets are available – such as translation corpuses – and
those for which it is not, with much more rapid progress in the
former.

One domain suffering from such data scarcity is hand-drawn images.
Visual expression is a fundamental human trait with deep connections
to perception and creativity, yet most of our understanding of the
drawing process is purely qualitative. Although a quick Google
search yields million of line drawings, these images are stored in
raster format with little or no semantic annotation. Given this
state of affairs, a great many fascinating questions about human
drawing cannot be answered quantitatively. An ideal drawing corpus
would be annotated by artist and subject allowing us to measure
variation in ``drawing style'' across a single subject, while
illumination how one artist's style varies across subjects. Another
goal would be to have precise stroke-level data, including timing
and order. Such stroke information could allow us to rigorously
answer questions about the order in which artists draw lines, and
how quickly. We might even glean semantic knowledge about the
subject by understanding the temporal relationships among strokes.
Going further, drawings are meant to be recognized and understood by
others. Ideally, a drawing corpus could shed light on these issues,
for example: which strokes were most salient in conveying the
subject? Finally, for statistical purposes, we would like a
\emph{large} dataset, with many drawing by the same artist and many
drawings of the same subject.

To address these issues, we have developed an iPhone game called
\emph{DrawAFriend}, which is intended to generate millions of
hand-drawn images containing all of the information described above.
In comparison with previous work which studied simple line drawings
\adrien{[cite Hayes and Shadowdraw]}, we focus on face portraits.
Such drawings are exceedingly difficult to draw by hand, and even
more so using a touch interface. Therefore, we decided to allow
players to trace over existing photographs. Even within this
restricted setting, we observe startling variation in drawing style
\adrien{maybe this should be the teaser image?}. Moreover, when
multiple artists trace the same face, we get the added benefit that
all drawings are in geometric correspondence, which can lead to much
simplified analysis. In contrast to previous work which generated
drawings through Amazon Mechanical Turk, our use of a game to
generate data brings the added challenge that the game must be
rewarding and encourage repeated play. We address this challenge by
allowing player to draw mutual friends on the social network as well
as celebrities. We phrase the challenge as a guessing game, with the
important corollary that we can learn \emph{when} a particular face
was recognized, i.e. which strokes were necessary for recognition.
The success our game design is born out in the numbers: within
DrawAFriend's first \textbf{X} days on the market, we generated
\textbf{Y} images, all with stroke-level information.

We believe that the completely new, data-rich corpus generated by
this game will allow us to solve numerous fascinating questions,
including those delineated above. In this paper, we focus on
studying how such a large database can help us create
self-correcting touch-based interactions on mobile devices. We
observe that drawing with a touch device often suffers from the
``fat finger'' problem. We factor this issue into two elements: (1)
the ``intent'' of the artist in drawing a stroke, and (2) an
additional random noise component caused by inaccuracy in the touch
interface. We therefore hypothesize that if strokes are ``average''
(in an appropriate sense) over a sufficiently large database of
drawings, then we can cancel out the noise and recover the original
intent. Furthermore, this data can allow us to develop a
``self-correcting'' touch interface: in essence, we can clean up the
artists drawing in real time by using data from hundreds of previous
drawings of the same subject. To solve this problem, we present a
new metric for ``local stroke coherence,'' that is, regions of the
images where many artists agree. We further present a surprisingly
simple method to correct strokes based on this metric making it
significantly easier to draw faces.

More generally, we consider the DrawAFriend corpus to be a
significant contribution which will benefit research by the graphics
community, and we hope that our game design insights might guide
other researchers seeking to collect large datasets in domains
suffering from data scarcity.


% - fat finger problem	
% 	- althogh we believe
% 	- with applications from automated graphic training to
% 	
% 
% 	- problem with drawing using touch interfaces
% 	- naively we can use zooming but this isn't fun
% 	- how can we leverage many drawings
% 	- our insight: average strokes are good
% 
% 	- this simple method can clean up many strokes, 
% 	- more generally
% 		- valuable corpus which we will make available to the community
% 		- and will also yield design patterns
% 		which we can reuse to incentivize large groups to generate further
% 		datasets,
% 
% To solve this problem, my research uses social networking mechanism
% to elicit large datasets that have never been assembled before. As a
% model problem, I am working on human drawing.  Nonetheless, recent work by my colleagues and I
% shed light on the power of computation to illuminate fundamental
% aspects of this process. At Princeton, I worked on a highly cited
% SIGGRAPH paper which computationally analyized line drawings. To
% achieve this result however, we painstakingly set up workshops where
% artists would draw pre-selected objects. The dataset itself only
% included 208 line drawings from 29 artists. This work inspired my
% collaborators to develop ShadowDraw, which demonstrated that large
% image datasets can be leveraged a real-time free-hand drawing
% guidance software which leverages a large database of images from
% the internet. Unsupervised learning on thousands or millions of
% drawings would be groundbreaking. The creation of this dataset was
% not possible until Facebook integration and my project, DrawAFriend.
