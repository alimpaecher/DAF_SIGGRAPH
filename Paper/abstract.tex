Touch-screen interfaces have inspired a new generation of drawing
applications. However, small screens and inaccurate touch
localization -- the ``fat finger'' problem -- remains a principal
challenge for such direct-manipulation interfaces. We address this
problem in two phases. First, we assemble a corpus of aligned
drawings via a new iPhone game we developed specifically for the
purpose of collecting drawing data. Second, by analyzing the
database of drawings, we build a spatially varying model of artistic
consensus at the stroke level. Using this model, we introduce a
surprisingly simple method to improve strokes in real-time.
Importantly, our corrections appear nearly invisible to the user,
seamlessly preserving artistic intent while simplifying touch-based
drawing.